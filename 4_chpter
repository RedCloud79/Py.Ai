**************************************1
import tensorflow as tf

mnist = tf.keras.datasets.mnist

(X, YT), (x, yt) = mnist.load_data()

print(YT[0])
print(YT[:10])
print(tf.one_hot(YT[0],10))
print(tf.one_hot(YT[1],10))
print(tf.one_hot(YT[1],10).numpy())
print(tf.one_hot(YT[:10],10).numpy())

import numpy as np
print(np.argmax(tf.one_hot(YT[:10],10)))

# X, x = X/255, x/255
# X, x = X.reshape((60000,784)), x.reshape((10000,784)) # 데이터를 핌
# 
# 
# model = tf.keras.Sequential([ 
#     tf.keras.Input(shape=(784,)),
#     tf.keras.layers.Dense(128, activation='relu'),
#     tf.keras.layers.Dense(1, activation='softmax'),
#     ]) # 신경망 모양
# 
# model.compile(optimizer='adam',
#               loss='sparse_categorical_crossentropy'
#               metrics=['accuracy']) # 오차 함수, metrics 얼마나 맞추는지
# 
# model.fit(X,YT,epochs=50)
# 
# model.evaluate(x,yt) # predict도 사용가능
# 
# y=model.predict(x[:16])
# print(y)


********************************************2
import tensorflow as tf

mnist = tf.keras.datasets.mnist

(X, YT), (x, yt) = mnist.load_data()


X, x = X/255, x/255
X, x = X.reshape((60000,784)), x.reshape((10000,784)) # 데이터를 핌


model = tf.keras.Sequential([ 
    tf.keras.Input(shape=(784,)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax'),
    ]) # 신경망 모양

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy']) # 오차 함수, metrics 얼마나 맞추는지

model.fit(X,YT,epochs=5)

model.evaluate(x,yt) # predict도 사용가능

model.save('hand_made.h5')

***********************************************3
import tensorflow as tf

mnist = tf.keras.datasets.mnist

(_,_),(x,yt) = mnist.load_data()
x/=255
x.reshape((10000,784))

model.tf.keras.models.load_model('hand_made.h5')

y=model.predict(x[:1])
print(y[0])

****************************************************4
import tensorflow as tf

mnist = tf.keras.datasets.mnist

(_,_),(x,yt) = mnist.load_data()
x=x/255
x = x.reshape((10000,784))

model = tf.keras.models.load_model('hand_made.h5')
import numpy as np
np.set_printoptions(precision=2, suppress=True)

y=model.predict(x[:1])
print(y[0])
print(yt[0])
print(np.argmax(y[0]))

********************************************************5
import tensorflow as tf
import numpy as np
mnist = tf.keras.datasets.cifar10

(X, YT), (x, yt) = mnist.load_data()
print(X.shape, YT.shape, x.shape, yt.shape)
import matplotlib.pyplot as plt
plt.imshow(X[0][0:32,0:32,2], cmap='Greens') #색깔 부분만 흑백형태로 표현
# plt.show()

for row in range(32):
    for col in range(32):
        print('%4d' %X[0][:,:,0][row][col], end='')
    print()
print(np.min(X), np.max(X))

********************************************************6
import tensorflow as tf
import numpy as np
mnist = tf.keras.datasets.cifar10

(X, YT), (x, yt) = mnist.load_data()
print(X.shape, YT.shape, x.shape, yt.shape)
import matplotlib.pyplot as plt
plt.imshow(X[0][0:32,0:32,2], cmap='Greens') #색깔 부분만 흑백형태로 표현
# plt.show()

# for row in range(32):
#     for col in range(32):
#         print('%4d' %X[0][:,:,0][row][col], end='')
#     print()
# print(np.min(X), np.max(X))
X, x = X/255, x/255
X, x = X.reshape((50000,3072)), x.reshape((10000,3072)) # 데이터를 핌


model = tf.keras.Sequential([ 
    tf.keras.Input(shape=(3072,)),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dropout(0.2),# 신경망을 끊어서 변수를 준다.
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='linear'),
    ]) # 신경망 모양

model.compile(optimizer='adam',
              loss='mse',
              metrics=['accuracy']) # 오차 함수, metrics 얼마나 맞추는지

model.fit(X,YT,epochs=5)

model.evaluate(x,yt) # predict도 사용가능

model.save('cifar10_1.h5')

************************************************************7
import tensorflow as tf
import numpy as np
mnist = tf.keras.datasets.cifar100

(X, YT), (x, yt) = mnist.load_data()
# print(X.shape, YT.shape, x.shape, yt.shape)
# print(np.max(YT))
import matplotlib.pyplot as plt
plt.imshow(X[0]) #색깔 부분만 흑백형태로 표현
# plt.show()

# for row in range(32):
#     for col in range(32):
#         print('%4d' %X[0][:,:,0][row][col], end='')
#     print()
# print(np.min(X), np.max(X))
X, x = X/255, x/255
X, x = X.reshape((50000,3072)), x.reshape((10000,3072)) # 데이터를 핌


model = tf.keras.Sequential([ 
    tf.keras.Input(shape=(3072,)),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dense(100, activation='softmax'),
    ]) # 신경망 모양

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy']) # 오차 함수, metrics 얼마나 맞추는지

model.fit(X,YT,epochs=5)

model.evaluate(x,yt) # predict도 사용가능

# model.save('cifar10_1.h5')

*************************************************************************8
#랜덤한 값을 주는 코드
import tensorflow as tf
import numpy as np
np.set_printoptions(precision=2, suppress=True)

np.random.seed(3) # 일정한 값을 추출할 수 있다.
X = np.random.randint(0,2,(10,7))
YT = np.random.randint(0,2,(10,4))

print(X.shape, YT.shape)

model = tf.keras.Sequential([
    tf.keras.Input(shape=(7,)),
    tf.keras.layers.Dense(16, activation = 'relu'),
    tf.keras.layers.Dense(16, activation = 'relu'),
    tf.keras.layers.Dense(4, activation = 'sigmoid'),
    ])

model.compile(optimizer='adam',
              loss = 'mse'
              )
model.fit(X,YT,epochs=1000)
Y = model.predict(X)
print(Y)
print(YT)
*********************************************************************9
import tensorflow as tf
import numpy as np
np.set_printoptions(precision=1, suppress=True)

#np.random.seed(3)
X = np.random.randint(0,2,(20,17))
YT = np.random.randint(0,2,(20,14))

print(X.shape, YT.shape)

model = tf.keras.Sequential([
    tf.keras.Input(shape=(17,)),
    tf.keras.layers.Dense(32, activation = 'relu'),
    tf.keras.layers.Dense(32, activation = 'relu'),
    tf.keras.layers.Dense(14, activation = 'linear'),
    ])

model.compile(optimizer='adam',
              loss = 'mse'
              )
model.fit(X,YT,epochs=2000)

Y = model.predict(X)
print(Y)
print(YT)

***********************************************************10
import tensorflow as tf
import numpy as np
np.set_printoptions(precision=1, suppress=True)

#np.random.seed(3)
X = np.random.randint(0,256,(60000,32,32,3))
YT = np.random.randint(0,10,(60000,))
import matplotlib.pyplot as plt
print(YT[0])
plt.imshow(X[0])
# plt.show()

print(X.shape, YT.shape)
X=X/255
X=X.reshape(60000,3072)


model = tf.keras.Sequential([
    tf.keras.Input(shape=(3072,)),
    tf.keras.layers.Dense(512, activation = 'relu'),
    tf.keras.layers.Dense(10, activation = 'softmax'),
    ])

model.compile(optimizer='adam',
              loss = 'sparse_categorical_crossentropy',
              metrics=['accuracy']
              )

model.fit(X,YT,epochs=10)

Y = model.predict(X)
print(Y)
print(YT)


*****************************************************************************************************
## CNN 알고리즘의 이해와 구현 (합성곱 신경 망)

# CNN의 순전파 이해와 구현(Convolution Neural Network)
- Conveolution과 pooling을 통해 그림의 특징을 추출해낸다.


ex_1) cnn 형태의 코드
import tensorflow as tf

mnist = tf.keras.datasets.fashion_mnist

(X,YT),(x,yt) = mnist.load_data()

X,x = X/255,x/255
X = X.reshape(60000,28,28,1)
x = x.reshape(10000,28,28,1)

model = tf.keras.Sequential ([
    tf.keras.Input(shape=(28,28,1)),
    tf.keras.layers.Conv2D(32,(3,3), activation = 'relu',padding='same'),
    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu',padding='same'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation = 'relu'),
    tf.keras.layers.Dense(10, activation = 'softmax')
    ])

model.compile(optimizer = 'adam',
              loss = 'sparse_categorical_crossentropy',
              metrics = ['accuracy'])
model.fit(X,YT,epochs = 5)

model.evaluate(x,yt)

* filter size .3x3 입력
ex_1)
import numpy as np

X = np.random.randint(0,256,(3,3,1))

import matplotlib.pyplot as plt
plt.imshow(X)
plt.show()
print(X[0:3,0:3,0])

F = np.random.randint(0,256,(3,3,1))
plt.imshow(F)
plt.show()
print(F[:,:,0])

plt.imshow(X*F)
plt.show()
print((X*F)[:,:,0])
print(np.sum(X*F)) # 컨벌루션(합성곱)
*결과값
[[ 90  69 122]
 [218 231 250]
 [184 148 157]]
[[  4 124 165]
 [  1 125  89]
 [196  61 172]]
[[  360  8556 20130]
 [  218 28875 22250]
 [36064  9028 27004]]
152485

* 합성곱
import numpy as np

np.random.seed(1)

image = np.random.randint(5, size=(3,3))
print('image =\n', image)

filter = np.random.randint(5, size=(3,3))
print('filter =\n', filter)

image_x_filter = image * filter
print('image_x_filter =\n', image_x_filter)

convolution = np.sum(image_x_filter)
print('convolution =\n', convolution)
*결과값
image =
 [[3 4 0]
 [1 3 0]
 [0 1 4]]
filter =
 [[4 1 2]
 [4 2 4]
 [3 4 2]]
image_x_filter =
 [[12  4  0]
 [ 4  6  0]
 [ 0  4  8]]
convolution =
 38
 
# stride .4x4 입력
- 1또는 2픽셀씩 이동하면서 추출하여 2X2와 같은형태로 만들어낸다.

ex_2)
import numpy as np

np.random.seed(1)

image = np.random.randint(5, size=(4,4))
print('image =\n', image)

filter = np.random.randint(5, size=(3,3))
print('filter =\n', filter)

convolution = np.zeros((2,2))

for row in range(2):
    for col in range(2):
        window = image[row:row+3, col:col+3]
        print('window(%d, %d) = \n' %(row,col), window)
        print('window(%d, %d)*filter = \n' %(row,col), window*filter)
        convolution[row, col] = np.sum(window*filter)
        
print('convolution =\n', convolution)
*결과값
image =
 [[3 4 0 1]
 [3 0 0 1]
 [4 4 1 2]
 [4 2 4 3]]
filter =
 [[4 2 4]
 [2 4 1]
 [1 0 1]]
window(0, 0) = 
 [[3 4 0]
 [3 0 0]
 [4 4 1]]
window(0, 0)*filter = 
 [[12  8  0]
 [ 6  0  0]
 [ 4  0  1]]
window(0, 1) = 
 [[4 0 1]
 [0 0 1]
 [4 1 2]]
window(0, 1)*filter = 
 [[16  0  4]
 [ 0  0  1]
 [ 4  0  2]]
window(1, 0) = 
 [[3 0 0]
 [4 4 1]
 [4 2 4]]
window(1, 0)*filter = 
 [[12  0  0]
 [ 8 16  1]
 [ 4  0  4]]
window(1, 1) = 
 [[0 0 1]
 [4 1 2]
 [2 4 3]]
window(1, 1)*filter = 
 [[0 0 4]
 [8 4 2]
 [2 0 3]]
convolution =
 [[31. 27.]
 [45. 23.]]

# padding .6x6입력
- 반복적으로 합성 곱을 수행하면 이미지의 크기가 점점 작아지는걸 보완하기 위한 함수
- 4x4의 이미지를 zero padding을 하여 6x6으로 변경한후 합성 곱을 수행한다.

ex_1) 6x6 zero pading입력
import numpy as np

np.random.seed(1)

image = np.random.randint(5, size=(4,4))
print('image =\n', image)

filter = np.random.randint(5, size=(3,3))
print('filter =\n', filter)

image_pad = np.pad(image,((1,1), (1,1)))
print('image_pad =\n', image_pad)

convolution = np.zeros((4,4))

for row in range(4):
    for col in range(4):
        window = image_pad[row:row+3, col:col+3]
        convolution[row, col] = np.sum(window*filter)
        
print('convolution =\n', convolution)
*결과값
image =
 [[3 4 0 1]
 [3 0 0 1]
 [4 4 1 2]
 [4 2 4 3]]
filter =
 [[4 2 4]
 [2 4 1]
 [1 0 1]]
image_pad =
 [[0 0 0 0 0 0]
 [0 3 4 0 1 0]
 [0 3 0 0 1 0]
 [0 4 4 1 2 0]
 [0 4 2 4 3 0]
 [0 0 0 0 0 0]]
convolution =
 [[16. 25. 10.  4.]
 [38. 31. 27.  7.]
 [28. 45. 23. 16.]
 [42. 48. 49. 28.]]

# pooling .4x4 합성곱
- 4개의 데이터를 모아서 1개로 만드는 작업
- 4x4의 경우 2x2의 형태로 모아주는것
- max pooling = 가장 큰값을 뽑아내는 것, everage pooling = 다합하여 평균값을 넣는다.

ex_1)
import numpy as np

np.random.seed(1)

image = np.random.randint(5, size=(4,4))
print('image =\n', image)

filter = np.random.randint(5, size=(3,3))
print('filter =\n', filter)

image_pad = np.pad(image,((1,1), (1,1)))
print('image_pad =\n', image_pad)

convolution = np.zeros((4,4))

for row in range(4):
    for col in range(4):
        window = image_pad[row:row+3, col:col+3]
        convolution[row, col] = np.sum(window*filter)
        
print('convolution =\n', convolution)

max_pooled = np.zeros((2,2))

for row in range(4):
    for col in range(4):
        window = convolution[2*row:2*row+2, 2*col:2*col+2]
        max_pooled[row, col] = np.max(window)
        
print('max_pooled = \n', max_pooled)


























