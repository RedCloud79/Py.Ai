## 인공지능

인공지능 > 머신러닝 > 딥러닝

* 인공 신경망
- 인간의 중앙 신경계로부터 영가을 얻어 만들어졌다.

*신경망의 구조
- 입력층, 은닉층, 출력층의 구조로 이루어져 있고, 은닉층이 2층 이상일 때 심층 신경망(DNN)이라고 합니다.
- CNN(이미지의 특징을 뽑아내는 인공 신경망과 분류를 위한 인공 신경망)
- RNN(Recurrent Neural Network structure) 반복 신경망

@ 실제로 적용된 응용의 예
● 얼굴 확인하기
● 음성 인식하기
● 손 글씨 읽기
● 문장 번역하기
● 게임하기 (보드게임이나 카드 게임)
● 자동차나 로봇 제어하기
● 그리고 더많은 것들


* 완전 연결 층 ( fully connected artificial neural network )
- 완전 연결 인공 신경망

# 인공 신경망의 학습 방법
* 지도 학습
- 1. 하나의 입력 데이터를 처리합니다. 2. 출력값을 미리 알려진 결과와 비교합니다. 3. 인공 신경망을 수정합니다.
4. 이 과정을 반복합니다.

* 비지도 학습
- 입력 값을 그대로 기억해 내야 하는 형태의 학습 방법을 비지도 학습이라고 한다.

* 강화 학습
- 시행 착오를 통해 이익이 되는 동작을 취할 확률은 높이고 손해가 되는 동작을 취할 확률을 낮추는 학습.


# 인공 신경 내부 살펴보기
- weight(가중치) = 곱셈 연산이 들어간다.
- sum up(신호의 더하기)
- activate(활성화) = 신호를 조정을 한다. 큰 신호를 줄여서 조절을 한다.

* 활성화 함수( Activation Function )
- Sigmoid
- ReuLu = max(0,x)
- softmax(활성화 함수) = 출력의 모든 합을 '1'로 만들어 낸다.

# 인공 신경 함수 수식
1. 입력 값 x의 집합, 2. 입력값에 대한 가중치 w의 집합, 3. 편향 입력 값 1, 4. 편향 b, 5 가중치와 편향을 통해
들어오는 이볅 값들의 합. 6. 그 합을 입력으로 받는 활성화 함수 f, 7. 활성화 함수 f의 출력 out을 나타낸다.


# 가장 간단한 인공 신경망
- 1개의 입력을 받는경우 출력이 1개 : y(출력값) = x(입력값)*w(가중치) + 1(편향 입력 값)*b(편향)


## 딥러닝 7 공식
- 순전파, 목표값, 오차, 역전파 오차, 역전파, 학습률과 같은 용어의 이해 해야한다.

* 순전파 = y = x*w + 1*b
- 입력 노드 1개, 출력 노드 1개, 편향으로 구성된 단일 인공 신경망
ex_1)
x = 2
w = 3
b=1
y=x*w + 1*b
y
결과값 : 7

* 역전파 = wE = yE*x
           bE = yE*1

* 평균 제곱 오차 = E = (y-yT)*(y-yT) / 2
- y는 순전파에 의한 예측값, yT는 목표값 또는 라벨을 나타낸다. 오차, 손실, 비용이라고도 합니다.
ex_2) y값으로 7을 얻었지만, y로 10이 나오게 하려고한다. E(오차값)
yT = 10
E=(y-yT)**2/2
E
결과값 : 4.5

* 역전파 오차 = yE = y - yT
- yE는 역전파 오차, y는 순전파에 의한 예측값, yT는 목표값
ex_3)
yE = y-yT
yE
결과값 : -3

* 입력 역전파 = xE = yE*w
- 오차(yE)를 입력값(xE)로 다시 보낸다. (편향은 무시한다.)















