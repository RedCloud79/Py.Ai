## 텐서플로우로 딥러닝 구현하기

# 1입력 1출력 ( 'numpy'라는 행렬을 활용 )
* X(입력값), T(목표 값), W(가중치), B(편향)
* tensorflow = Sequential( 순차적으로 처리를 해주는 신경망 )
* optimizer = 아담(Adam)의 활용도(성능)가 높다.
* W,B의 값을 건들경우는 거이 없다.
* model.save() 로 외부에 저장하는 방식이 보통.
* cnn의 신경망 형태로 할 경우 학습률이 올라간다.

# 1입력 1출력 인공신경
ex_1) dnn_test (기본적인 틀 코드)
import tensorflow as tf
import numpy as np

X = np.array([[2]])
YT = np.array([[10]])
W=np.array([[3]])
B=np.array([1])

model = tf.keras.Sequential([
    tf.keras.Input(shape=(1,)),
    tf.keras.layers.Dense(1)
])

model.layers[0].set_weights([W,B])

model.compile(optimizer = 'sgd',
              loss='mse')

Y = model.predict(X)
print(Y)

model.fit(X,YT,epochs=1000)

print('W=',model.layers[0].get_weights()[0])
print('B=',model.layers[0].get_weights()[1])

Y = model.predict(X)
print(Y)
* 결과값
W= [[4.1999974]]
B= [1.6000019]
1/1 [==============================] - 0s 16ms/step
[[9.999997]]


# 2입력 1출력의 예제
ex_1)
import tensorflow as tf
import numpy as np

X = np.array([[2,3]])
YT = np.array([[27]])
W=np.array([[3],[4]])
B=np.array([1])

model = tf.keras.Sequential([
    tf.keras.Input(shape=(2,)),
    tf.keras.layers.Dense(1)
])

model.layers[0].set_weights([W,B])

model.compile(optimizer = 'sgd',
              loss='mse')

Y = model.predict(X)
print(Y)

model.fit(X,YT,epochs=1000)

print('W=',model.layers[0].get_weights()[0])
print('B=',model.layers[0].get_weights()[1])

Y = model.predict(X)
print(Y)
* 결과값
W= [[4.1428566]
 [5.714285 ]]
B= [1.5714294]
1/1 [==============================] - 0s 16ms/step
[[26.999998]]

# 2입력 2출력의 예제
ex_1)
import tensorflow as tf
import numpy as np

X = np.array([[2,3]])
YT = np.array([[27, -30]])
W=np.array([[3,5],[4,6]])
B=np.array([1,2])

model = tf.keras.Sequential([
    tf.keras.Input(shape=(2,)),
    tf.keras.layers.Dense(2)
])

model.layers[0].set_weights([W,B])

model.compile(optimizer = 'sgd',
              loss='mse')

Y = model.predict(X)
print(Y)

model.fit(X,YT,epochs=1000)

print('W=',model.layers[0].get_weights()[0])
print('B=',model.layers[0].get_weights()[1])

Y = model.predict(X)
print(Y)
* 결과값
W= [[ 4.1428556 -3.5714262]
 [ 5.714284  -6.857143 ]]
B= [ 1.5714294 -2.2857132]
1/1 [==============================] - 0s 16ms/step
[[ 26.999994 -29.999994]]


# 2입력 2은닉 2출력의 예제
ex_1)
import tensorflow as tf
import numpy as np

X = np.array([[.05,.10]])
YT = np.array([[.01, .99]])
W=np.array([[.15,.25],[.20,.30]])
B=np.array([.35,.35])
W2=np.array([[.40,.50],[.45,.55]])
B2=np.array([.60,.60])

model = tf.keras.Sequential([
    tf.keras.Input(shape=(2,)),
    tf.keras.layers.Dense(2),
    tf.keras.layers.Dense(2)
])

model.layers[0].set_weights([W,B])
model.layers[1].set_weights([W2,B2])

model.compile(optimizer = 'sgd',
              loss='mse')

Y = model.predict(X)
print(Y)

model.fit(X,YT,epochs=1000)

print('W=',model.layers[0].get_weights()[0])
print('B=',model.layers[0].get_weights()[1])
print('W2=',model.layers[1].get_weights()[0])
print('B2=',model.layers[1].get_weights()[1])

Y = model.predict(X)
print(Y)
* 결과값
W= [[0.14315726 0.24180055]
 [0.18631484 0.2836011 ]]
B= [0.2131526  0.18600278]
W2= [[0.20264395 0.53349453]
 [0.2525947  0.5828034 ]]
B2= [-0.09561112  0.73054373]
1/1 [==============================] - 0s 16ms/step
[[0.01000983 0.9899955 ]]


## 딥러닝 활용 맛보기
- 손글씨 숫자 데이터를 입력받아 학습을 수행하는 예제
- 28*28*1*60000개 : 훈련용, 28*28*1*10000개 : 검증용
- 입력 = input layer 784, 은닉 = hidden layer 128(relu), 출력 = output layer 10(softmax)
- Loss Layer (cross-entropy) 오차 함수

# 활용의 예시
ex_1) 손글씨 숫자 인식 예제
import tensorflow as tf

mnist = tf.keras.datasets.mnist # fashion_mnist 의류와 관련된 데이터

(X, YT), (x, yt) = mnist.load_data()
# print(X.shape, YT.shape, x.shape, yt.shape,) = 모양을 찍어보는 코드

# pip3 install matplotlib 다운로드 필요
from matplotlib import pyplot as plt
plt.imshow(X[0])
plt.show()
print(YT[0]) # YT의 값 출력
print(tf.one_hot(YT[0], 10)) * 출력값 : tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0.], shape=(10,), dtype=float32)

--------------------------------------------- # 숫자로 데이터모양을 표기
for row in range(28):
    for col in range(28):
        print('%4s' %X[0][row][col], end='')
    print()
    
import numpy as np

plt.figure(figsize=(10,10)) # 가로5 세로5의 데이터를 불러옴
for i in range(25):
    plt.subplot(5,5,i+1) # 세로, 가로 = 5
    plt.xticks([])
    plt.yticks([])
    plt.imshow(X[i],cmap=plt.cm.binary) #binary = 128기준으로 크면 검정 작으면 흰색
    plt.xlabel(YT[i])
plt.show()
----------------------------------------------
X, x = X/255, x/255
X, x = X.reshape((60000,784)), x.reshape((10000,784)) # 데이터를 핌
print(X.shape)

model = tf.keras.Sequential([
    tf.keras.Input(shape=(784,)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax'),
    ]) # 신경망 모양

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy']) # 오차 함수, metrics 얼마나 맞추는지

model.fit(X,YT,epochs=5)

model.evaluate(x,yt) # predict도 사용가능
model.save('model.h5') # .h5 라는 확장자를 사용하여 저장

* 결과값
1875/1875 [==============================] - 3s 2ms/step - loss: 0.0443 - accuracy: 0.9862
313/313 [==============================] - 0s 901us/step - loss: 0.0796 - accuracy: 0.9751


# 학습한 모델파일을 활용 한 예시
ex_1)
import tensorflow as tf

mnist = tf.keras.datasets.mnist

(_,_),(x,yt) = mnist.load_data()

x=x/255
x=x.reshape((10000,784))

model = tf.keras.models.load_model('model.h5')

y = model.predict(x) # 한개만 추출할경우 y = model.predict(x[0:1])

print(y[0], yt[0])

import numpy as np

print(np.argmax(y[0]))

import matplotlib.pyplot as plt

x= x.reshape((10000,28,28))
plt.imshow(x[0])
plt.show()

plt.figure(figsize=(10,10)) # 출력
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(x[i],cmap=plt.cm.binary)
    plt.xlabel(np.argmax(y[i]))
plt.show()

------------------------------------------------
*틀린 것의 유무 확인 코드
cnt_wrong=0
y_wrong=[]
for i in range(10000):
    if np.argmax(y[i])!=yt[i]:
        y_wrong.append(i)
        cnt_wrong += 1
print(cnt_wrong)
print(y_wrong[:10])

* 인식못한 숫자 출력
plt.imshow(x[115])
plt.show()
print(np.argmax(y[115])), yt[115]
------------------------------------------------
* 인식못한 숫자를 5,5 싸이즈로 출력
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(x[y_wrong[i]],cmap=plt.cm.binary)
    plt.xlabel(f'{y_wrong[i]} : y{np.argmax(y[y_wrong[i]])} yt{yt[y_wrong[i]]}')
plt.show()
------------------------------------------------
*결과값
313/313 [==============================] - 0s 801us/step
[1.8032985e-07 1.7523572e-06 6.3887287e-06 2.1909325e-05 8.7815877e-08
 3.5283490e-06 1.4294808e-08 9.9996412e-01 3.9944635e-07 1.6487955e-06] 7
7
222
[115, 121, 199, 247, 259, 274, 321, 391, 445, 448]
8 4








